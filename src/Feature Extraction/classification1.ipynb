{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1\n",
    "### 1. We load all the images into training and test sets and resize them to 128x128:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = []\n",
    "image_test = []\n",
    "label_train = []\n",
    "images = []\n",
    "directory = \"./dataset\"\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    path = directory + \"/\" + filename\n",
    "    img = cv2.resize(cv2.imread(path, cv2.IMREAD_COLOR), (128, 128))\n",
    "    if \"train\" in filename:\n",
    "        label_train.append(filename.split(\"_\")[0])\n",
    "        image_train.append(img)\n",
    "    else:\n",
    "        image_test.append(img)\n",
    "    images.append(img)\n",
    "    \n",
    "image_train = np.array(image_train)\n",
    "image_test = np.array(image_test)\n",
    "label_train = np.array(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_col = 4\n",
    "nbins = 8\n",
    "def plot_all_hog(gradient):\n",
    "    nb_row = math.ceil(nbins / max_col) * 100\n",
    "    nb_plot = nb_row + max_col * 10\n",
    "    plt.figure(figsize = (20,10))\n",
    "    for i in range(nbins):\n",
    "        plt.subplot(nb_plot + i + 1)\n",
    "        plt.pcolor(gradient[:, :, i])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.title(\"HOG bin = \" + str(i)), plt.xticks([]), plt.yticks([])\n",
    "        plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. HoG Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog(img, plot=True):\n",
    "    cell_size = (4, 4)  # h x w in pixels\n",
    "    block_size = (4, 4)  # h x w in cells\n",
    "    nbins = 8  # number of orientation bins\n",
    "\n",
    "    hog = cv2.HOGDescriptor(_winSize=(img.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                      img.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                            _blockSize=(block_size[1] * cell_size[1],\n",
    "                                        block_size[0] * cell_size[0]),\n",
    "                            _blockStride=(cell_size[1], cell_size[0]),\n",
    "                            _cellSize=(cell_size[1], cell_size[0]),\n",
    "                            _nbins=nbins)\n",
    "\n",
    "    n_cells = (img.shape[0] // cell_size[0], img.shape[1] // cell_size[1])\n",
    "\n",
    "    # Compute HoG features\n",
    "    hog_feats = hog.compute(img)\\\n",
    "                   .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                            n_cells[0] - block_size[0] + 1,\n",
    "                            block_size[0], block_size[1], nbins) \\\n",
    "                   .transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n",
    "\n",
    "\n",
    "    # hog_feats now contains the gradient amplitudes for each direction,for each cell of its group for each group.\n",
    "    # Indexing is by rows then columns.\n",
    "\n",
    "    # computation for BlockNorm\n",
    "    gradients = np.full((n_cells[0], n_cells[1], nbins), 0, dtype=float)\n",
    "    cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "\n",
    "    for off_y in range(block_size[0]):\n",
    "        for off_x in range(block_size[1]):\n",
    "            gradients[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                      off_x:n_cells[1] - block_size[1] + off_x + 1] += \\\n",
    "                hog_feats[:, :, off_y, off_x, :]\n",
    "            cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                       off_x:n_cells[1] - block_size[1] + off_x + 1] += 1\n",
    "\n",
    "    # Average gradients\n",
    "    gradients /= cell_count\n",
    "    \n",
    "    # Preview\n",
    "    if plot:\n",
    "        plt.figure(figsize = (10,10))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(\"Original Image\"), plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "        bin = 0 # angle is 360 / nbins * direction\n",
    "        plot_all_hog(gradients)\n",
    "        plt.show()\n",
    "    return gradients\n",
    "\n",
    "def hog_images(images, plot=False):\n",
    "    imgs = []\n",
    "    for img in images:\n",
    "        val = hog(img, plot)\n",
    "        imgs.append(val)\n",
    "    \n",
    "    return imgs\n",
    "\n",
    "hog_train_imgs = np.array(hog_images(image_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "train_vals = hog_train_imgs.reshape(hog_train_imgs.shape[0], -1)\n",
    "neigh.fit(train_vals, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_vals = np.array(hog_images(image_test, plot=True))\n",
    "test_vals = test_vals.reshape(test_vals.shape[0], -1)\n",
    "\n",
    "print(neigh.predict(test_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Reasoning Questions\n",
    "### 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HoG is not rotation invariant meaning that if you calculate HoG on an image and calculate HoG on a rotated version of that image, the results will not be the same. For a classification example you could also include rotated images into your training set to make your classifier better recognize them. Another approach could be to use another feature detector such as SIFT which is rotation invariant. One approach to ensure all logos have a uniform orientation is to maintain one image for each class we are trying to classify that we know is oriented in the right direction. Then for every logo that comes in, we would need to calculate the SIFT features, match them between the two images and rotate the images such that they match. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)\n",
    "There would be two gradients needed to accurately depict the picture. This is because with only one gradient, you would not be able to distinguish between the left most image and the other two images. With the second gradient direction we would be able to have two reference points and uniquely identify all the images. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
